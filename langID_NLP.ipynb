{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Kt1fyVMmyyc5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "import re\n",
    "from nltk import ngrams\n",
    "from collections import defaultdict\n",
    "import nltk\n",
    "import collections\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "zcHt-U5X0Qk0"
   },
   "outputs": [],
   "source": [
    "# Read data \n",
    "X_train = open('x_train.txt',encoding=\"utf8\").read().split('\\n')\n",
    "Y_train = open('y_train.txt',encoding=\"utf8\").read().split('\\n')\n",
    "labels = pd.read_csv('labels.csv',delimiter = ';')\n",
    "Y_train =  Y_train[:10000]\n",
    "X_train =  X_train[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "lgaeru6_AWpW"
   },
   "outputs": [],
   "source": [
    "# Remove unnecessary characters from data\n",
    "extras = '!\"$%&/{}[]()=?\\\\`´*+~#-_.:,;<>|1234567890°-\\'' # Characters to remove from data\n",
    "rx = '[' + re.escape(''.join(extras)) + ']'\n",
    "x_train =[] \n",
    "for example in X_train:\n",
    "    x_train.append(re.sub(' +', ' ',re.sub(rx, '', example)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "Dh1WIZ_bAkZA"
   },
   "outputs": [],
   "source": [
    "# Convert language labels to language Name => 'en' -> 'English'\n",
    "lab_dict = { labels.loc[i]['Label']:labels.loc[i]['English'] for i in range(0,len(labels))}\n",
    "y_train = [lab_dict[item] if item != 'nan' else 'Min Nan Chinese' for item in Y_train ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "jNBMCn3bA078"
   },
   "outputs": [],
   "source": [
    "# Collecting examples belonging to same language\n",
    "# lang_2_ex = { 'English' : [ 'Welcome to ..', 'PHP sucks ...', ...] , 'Spanish' : ['dads....', 'dasdsa...',....] , ....}\n",
    "\n",
    "lang_2_ex = defaultdict(list)\n",
    "for i in range(len(x_train)):\n",
    "    lang_2_ex[y_train[i]].append(x_train[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "y_gdP0c8ZGtJ"
   },
   "outputs": [],
   "source": [
    "# Creating ngrams for each language \n",
    "n=3 # trigram\n",
    "gram_per_lang = defaultdict(list)\n",
    "uniq_lang = set(y_train)\n",
    "for lang in uniq_lang:\n",
    "    for sent in lang_2_ex[lang]:\n",
    "        gram_per_lang[lang]+=[sent[i:i+n] for i in range(len(sent)-n+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "WT5Bp8t6ZJyz"
   },
   "outputs": [],
   "source": [
    "# Calculating frequency distribution for ngrams per language\n",
    "\n",
    "freq_per_lang = defaultdict(list)\n",
    "for lang in uniq_lang:\n",
    "    freq_per_lang[lang]=dict(zip(list(collections.Counter(gram_per_lang[lang]).keys()),list(collections.Counter(gram_per_lang[lang]).values()))) \n",
    "\n",
    "# https://stackoverflow.com/questions/12282232/how-do-i-count-unique-values-inside-a-list\n",
    "# https://stackoverflow.com/questions/209840/how-do-i-convert-two-lists-into-a-dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "nvnm5TxxZ3UK"
   },
   "outputs": [],
   "source": [
    "# Sorted Frequency Distribution \n",
    "\n",
    "sorted_freq_per_lang = defaultdict(list)\n",
    "for lang in uniq_lang:\n",
    "    sorted_freq_per_lang[lang] = {word : value for word,value in sorted(freq_per_lang[lang].items(),key=lambda item : item[1],reverse=True)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T2m7X2FGbQwM",
    "outputId": "5f33b831-8548-4cb4-b3f0-8a1bc1bd1a94"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 4283)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top 30 trigrams from each language\n",
    "\n",
    "features = []\n",
    "for lang, grams_dict in sorted_freq_per_lang.items():\n",
    "    i = 0\n",
    "    for gram,count in grams_dict.items():\n",
    "        if i <=40:\n",
    "            features.append(gram)\n",
    "        else:\n",
    "            break\n",
    "        i+=1\n",
    "    \n",
    "features = list(set(features))\n",
    "\n",
    "n = len(x_train)\n",
    "m = len(features)\n",
    "mat = np.zeros((n,m))\n",
    "mat.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for sent in x_train:\n",
    "    trigrams = [sent[i:i+3] for i in range(len(sent)-3+1)]\n",
    "    tri_dict = dict(zip(collections.Counter(trigrams).keys(),collections.Counter(trigrams).values()))\n",
    "    gram_count = []\n",
    "    for gram in features:\n",
    "        if gram in tri_dict.keys():\n",
    "            gram_count.append(tri_dict[gram]+1)\n",
    "        else:\n",
    "            gram_count.append(1)\n",
    "    mat[i] = gram_count\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 80.0%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(y_train)\n",
    "X_,x_test,Y_,y_test = train_test_split(mat,y,test_size=0.2,random_state=42)\n",
    "model = GaussianNB()\n",
    "model.fit(X_,Y_)\n",
    "x,y = x_test,y_test\n",
    "y_pred = model.predict(x)\n",
    "conf_matrix = confusion_matrix(y_pred=y_pred,y_true=y)\n",
    "acc = round(accuracy_score(y_pred=y_pred,y_true=y),2) * 100\n",
    "print(f\"Accuracy is {acc}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Copy of langID_NLP.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
